<html>
TheFourierTransformAndItsApplications-Lecture16
<p>
</p><p><b>Instructor (Brad Osgood)</b>:And we’re on.  I love it how they take me by surprise.

</p><p>All right.  Once again, let me call your attention to the midterm information.  I mentioned this on Friday; I also posted it up on the website and sent an email to the entire class, so the exam is on this Wednesday, Halloween.  Boo.  There are three sessions: 2:00 to 3:00 and 4:00 to 5:30 are both in the same location, it’s Building 380, that’s the math corner down in the basement 380W, and then from 6:00 to 7:00 it’s Skilling, that’s here.  Okay?

</p><p>I will bring copies of the exam, of course, and the bluebooks and also the formula sheet, all right; the same formula sheet that’s been posted on the Web for a long time so I’ll bring copies of that.  It is open books, open notes, you can bring whatever you want but don’t get ridiculous, as I said.

</p><p>It’s gonna cover stuff on up through sort of delta functions, properties of delta functions, generalized Fourier transforms, so it won’t talk about diffraction, it won’t talk about sampling, which is gonna be our next topic.  And I think that’s about it on the midterm; any questions about that, any issues that I have to know about for the midterm exam?  It’s a 90-minute exam.  And again, the idea is that I hope it’s gonna be sort of more conceptual than computational, although I say you can’t rub away all computations, obviously.  So anything else?

</p><p>Also, on – so we’ll have class on Wednesday.  It’s relentless.  Relentless.  As I also mentioned, the homework, the current homework assignment is not due till Friday.  The magnanimous Os has given you a couple of days so that’ll be on Friday.  And the current – the new homework assignment however, because it’s relentless, is already posted up on the web, on sampling.

</p><p>Yeah?

</p><p><b>Student:</b>Can we come to any of the sessions?

</p><p><b>Instructor (Brad Osgood)</b>:Yeah, but only one.  

</p><p><b>Student:</b>Okay.

</p><p><b>Instructor (Brad Osgood)</b>:I ask people to sign up just so I can get an idea about the size of the different sessions.  That was not a contract, it’s not written in stone, so if you want to change your mind that’s fine.  But as I say, you can only take the exam once.  Once, that’s the only deal.  Okay?  But any of the sessions should be okay.  I mean, you know, within some limits, I guess.  I don't even if the entire – I think the entire class could fit – so if everybody shows up at 6:00, I suppose everybody’ll fit in here but it might be a little tight.

</p><p>Yeah?  There’s another question.

</p><p><b>Student:</b>Does the material on the midterm cover the stuff that’s in the homework?

</p><p><b>Instructor (Brad Osgood)</b>:Sorry?  It doesn’t – well so the stuff that’s in the current homework?  Only to the extent, I guess there’s some generalized Fourier transforms, like you have to know the Fourier transform of the, you know, unit step function and signal function, and there were a couple of questions along those lines but nothing much sort of outside of that.  Okay?

</p><p>All right?  Okay.  All right, let’s move on.

</p><p>I want to talk a little bit more about diffraction actually.  And as a way of actually making a transition to our next topic, this may seem a little odd way – our next topic is sampling an interpolation.  And going from diffraction to sampling interpolation may seem like a little odd of way going but it’s – there’s an interesting connection here that I want to exploit.  The topic itself that I – the general areas of diffraction, and in particular what I want to talk about today, is interesting in itself and it does make actually for a nice link, so I want to talk about the problem of crystallography.  

</p><p>We’re gonna actually return to this when we have higher dimensional, when we talk about higher-dimensional Fourier transforms.  So today, I’m only gonna talk about the one-dimensional case, which of course is not realistic but it has some essential ideas that you find in the higher-dimensional case.  And as I say, it makes a nice transition to the next topic that we’re gonna be talking about.

</p><p>Let me remind you about the headline from last time.  So headline from last time, when we talked about diffraction and the Fourier transform, is that diffraction patterns are given by or determined by the Fourier transform of the apertures that cause the diffraction.  Of course, this simplifies things but that’s – if you’re looking for a quick summary of what our chief conclusion was last time, this is it.  Diffraction patterns are determined by the Fourier transform of the apertures or the aperture function.

</p><p>We had approximation; we talked about far-field diffraction, all the rest of that jazz, never mind.  That was all important, of course, but this is the main thing to be carried away with it, and that’s what I’m gonna be using today also.

</p><p>Now here is the setup for what was troubling people, what was puzzling people when x-ray crystallography, x-ray diffraction was first invented or first brought to bear on certain set of important problems.  So the setup that I want to talk about it as follows: x-rays were discovered in 1895 by Roentgen, of course, Roentgen, R-O-E-N-T-G-E-N, or some approximation of that spelling.  All right?

</p><p>Matter of fact, I remember actually in 1995 everybody was celebrating the 100th anniversary of x-rays, a very exciting time.  And the question was what are they?  Are they waves?  I mean their fundamental nature was not understand, so what are they, or what were they.  Are they waves, for example?  It was a new phenomenon.  If so, then certain considerations led them to conclude that the wavelengths should be about ten the minus eighth centimeters.  All right?

</p><p>If so, and the wavelength, which was too small to measure precisely, wavelength should be around ten to the minus eighth centimeters.  All right?  So that’s too small to measure by other means – by the means that we’re used to measuring different sorts of visible light, say, other sorts of waves which were diffraction gratings, too small to measure.  Let me just say too small to measure, period, with any of the standard techniques, okay, for example with diffraction gratings.

</p><p>On the other hand, or a different set of – a different line of questioning was crystals; 2.)  Crystals.  Been around for a long time and observed for a long time.  What are they?  In particular, it was clear from people – to people who were cutting them open, chiseling them around and making small crystals out of big crystals, that somehow the microscopic structure ought to be determined by the microscopic structure by the atomic structure.  And so, the conjecture was that crystals were crystals because there was a regular periodic array of the atoms that made them up.

</p><p>So microscopic structures should somehow be determined by the atomic structure, and the conjecture was the atomic structure should be a lead of some type.  That is the atoms were arrayed on some – in some regular pattern.  Atoms arrayed on a lattice.  How to test that, experimentally?

</p><p>All right, so there were famous experiments, series of experiments done in 1912 by Max von Laue, in 1912.  All right, so he purposed to study the physical – the nature of crystals by using x-rays to conduct diffraction experiments, so study the atomic structure of crystals via diffraction experiments with x-rays.  All right?  So he had a number of hypotheses then.  He had, first of all, a hypothesis that x-rays were waves.  And to assume that they’re waves means that they will exhibit diffraction.  They’ll exhibit the characteristic physical phenomena that are associated with waves: reflection, refraction, and, in this case, diffraction.

</p><p>So he had – the hypotheses were 1.)  X-rays are waves, some kind of waves of undetermined origin so will diffract.  Now, the diffraction pattern depends on the size of the aperture relative to the wavelength.  All right?  So he had a second hypothesis that crystals would serve as an appropriate diffraction grating.  That is to say, crystals are periodic, have a periodic atomic structure, maybe I should say lattice atomic structure, and the spacing of the – the spacing on the lattice, so the spacing of the atoms is comparable to the wavelength of the x-rays.  The spacing of the atoms is comparable to the wavelength of the x-rays.

</p><p>All right?  So that was the setup for his experiments.  And I’m gonna do a one-dimensional version of this.  I want to do – talk about the mathematics that comes up and how the Fourier transform comes in, in a one-dimensional version also.  Of course, everything here is three-dimensional.  Crystals are three dimensions, things are much more complicated.  The pictures that you get, the setup is much more complicated, but you can see some of the essential points if we already look at the one-dimensional picture.

</p><p>Now before I go on any further, since I am out of my depth here, has anybody ever done any experiments like this, anybody familiar with x-ray diffraction experiments or x-ray crystallography, anybody in materials or anything out there?  I have a lot of buddies who are material scientists, so I’m always afraid of one of them is gonna show up when I talk about this one day.

</p><p>All right.  Well you will, if you – so it’s really it’s a, by now of course a very standard experimental procedure, and quite refined and quite sophisticated.  But this how it looked at the beginning, and there’s a very important connection here with a Fourier transform, and a very fundamental fact that you have to know about the math in order to interpret the answers that you get, in order to interpret the results of your experiment.  And that’s really, what I want to get to.

</p><p>So let’s look at the one-dimensional version of this.  I’ll tell what you want to – I want to show what you want to measure, I want to say what you want to measure, and how you go about measuring it.  Or again, what I really want to is how the math shows you an important physical property of the – physical result of the experiments.

</p><p>All right, so I think of a one-dimensional crystal as an array of atoms along a line, as evenly spaced, let me just say, along a line, like so.  And let’s say the spacing is P.  I’ll get out of the way in just a second here.  P.  All right?  So they’re – the atoms are spaced P units apart, whatever the distance is.  And there’s effectively an infinite number of atoms because it is.  All right?  So it’s effectively an infinite line.  That’s actually very important in the math, an infinite array.

</p><p>Okay, now what you want to study – and the atoms are all identical.  All right?  What you want to study is, again for reasons, which I don't know, all right, but those who do the experiments understand this, so you want to study the so-called the electron density distribution for the entire crystal.  You want to study the electron density distribution for the crystal.  Now because the crystal consists of identical atoms arrayed, the idea is there’s an electron density distribution for the individual atom and then that’s replicated for the entire crystal.  Or, as we would say given the work we’ve done, it’s a periodized version of that.

</p><p>That is, so the electron density distribution for the crystal is then a periodized version of the electron density for a single atom.  All right?  So let’s say rho of X is the density, the electron density around a single atom.  Density for an atom, all right?  Then if you periodize it, the way we always periodize functions by summing up shifts, and write down a formula for that.

</p><p>So again, here’s the crystal with the atoms spaced P apart.  Here’s whatever it looks like.  Imagine this a description somehow of the density, let’s call it rho of X, so that describes the density of a given atom, and then that’s replicated for the entire crystal, or periodized for the entire crystal like that.  So let’s call that rho, the density for the crystal, and that’s the periodized version of the individual one.  So let’s say rho, so P of X indicating that spacing P apart, is the sum from K equals minus infinity to infinity of rho of X minus K times P.

</p><p>Okay?  That’s the standard formula for periodizing a function to get a function of period P.  That’s what the period should be, as dictated by the physical spacing of the atoms, P.  Okay?

</p><p>Okay, according to our headline from last time, the diffraction pattern should be the Fourier transform of this, or should be determined by the Fourier transform of this.  The diffraction pattern, which is what you want to see, a matter of fact it’s what you do see when you make the experiment.

</p><p>So you shine x-rays through the crystal, a bunch of spots or whatever, I shouldn’t say a bunch of spots because you don’t know what’s gonna happen, but a bunch of spots show up on the x-ray film.  And the pattern of the spots, the way the spots are arrayed, should be determined somehow by the Fourier transform.  Diffraction pattern determined by the Fourier transform of rho, so I want to find that.  Find this or find this in a – determine it in an effective enough way this is gonna allow you to interpret the results of the experiment.

</p><p>Okay, now to do that, I’m gonna write the periodization – I’m gonna do something new with the periodization that we haven’t done before.  We didn’t do when we were first – when we first studied it, but we have new techniques that are available to us now that allow us to carry the analysis a little bit further, a little bit differently than we did before.

</p><p>So I’m gonna write the periodized version as a convolution.  OP of X at a convolution, and I’m gonna invoke the convolution theorem.  Now you remember I can shift a function, it’s a sum – but what is the periodization?  The periodization is now, as it always was, a sum of shifted versions of the function.  You have a single function, and you shift it and you add them all up.  I can shift a function by convolving with a shifted delta function, so that is rho of X minus KP is rho of X convolved with delta of X minus KP.  

</p><p>And you notice I am now happy to write variables in my delta functions, if you don’t like it, tough.  All right?  I made a big deal out of the fact that deltas aren’t functions of points, they’re functions of functionals – they’re functionals and so on, but I feel no hesitancy in writing that.  Okay?

</p><p>That’s the shifted version.  You shift the function rho by convolving with the shifted delta function; that’s a basic property of delta functions.  All right, so the periodized version is the convolution of the fixed function rho with a sum of delta functions.  That is rho of X, rho P of X I’m calling it, that’s the sum minus infinity to infinity a rho of X minus KP.  That’s the sum, K equals minus infinity to infinity of rho of X, the fixed function convolved with the shifted delta function, X minus KP.  

</p><p>Or if I want to write, if I want to bring the – the rho is fixed here, doesn’t depend on K, so I could bring that outside the sum.  That is I write this as rho of X convolved with this big sum of delta, it’s shifted delta, K equals minus infinity to infinity delta of X minus KP.

</p><p>Okay now this object is gonna be an object of great interest and object of our study, so let me actually introduce right now a term for it, a notation for it, so I can work with it a little bit more.  Everybody with me, all right?  I haven’t done anything really differently than I’ve done before.  I’ve taken just a slightly different point of view toward the old process/procedure of periodizing a given function.

</p><p>So I want to use the notation – here, let me write it down and then I’ll pronounce it for you.  This is called the Shaw function or Shaw distribution, really, of spacing P.  All right?  That’s the Cyrillic letter, not drawn very well, or it’s my version of a Cyrillic letter, Shaw.  And as far as I know, actually this notion was introduced and popularized by Bracewell.  I don't know the history of it but is now pretty standard.  All right?

</p><p>And the reason why that particular symbol is chosen, or reason why Bracewell if indeed it is due to Bracewell, reason why he chose that letter was it was supposed to be reminiscent of the picture associated with this.  That is, if you would draw the picture associated with the sum of shifted delta functions, you would have bunch of arrows spaced P apart.  So zero P, two P, minus P, minus two P, and so on, infinitely many of them.  And three of them sticking up, make a Shaw.  I’m not making this up.  Okay?  That’s the pictorial representation of the Shaw distribution.

</p><p>All right, now what is the Fourier transform of this periodized electron density distribution?  Why use the convolution theorem?  Okay?  So I write rho of P of X then is rho of X convolved with the Shaw function with spacing P of X.  And if I’m interested in the Fourier transform because I want to understand the diffraction grating, I want to apply the convolution theorem.  So Fourier transform of rhos of P of X is the Fourier transform of the convolution which is the Fourier transform of rho, let me just write it like this without the variable.  It’s the Fourier transform of rho, I’ll get it, times the Fourier transform of Shaw.

</p><p>So the problem becomes how do you find the Fourier transform of Shaw?  All right.  This is a fixed function, depending on the nature of the crystal.  All right?  This is something – depend of the crystals just depends on where we have the spacing.  I don't have anything – I don't have any atoms in there, it just indicates that I put a delta function at each point on the line, spaced P apart, and the general crystal is defined by this convolution.

</p><p>To find the diffraction pattern, I want to find the Fourier transform of the fixed function, which is gonna be the same for every atom, for each individual atom rather, and then times the Fourier transform of the Shaw function.  So the question is:  What is that?  Ah, there’s a P here.  So what is, that’s the question.  All right now let me say a couple things about that.  It’s not obvious.  It’s not obvious and it’s remarkable, actually, what happens.  And we can analyze it very easily and rigorously with all that we’ve developed.

</p><p>So first of all, does it even make sense to consider something like that?  Well yes.  A given delta function is, of course, a distribution, it’s the simplest distribution, it’s the evaluation distribution, but I’m considering a huge sum here.  Does the sum really make sense?  I mean does an infinite sum of delta functions make sense.  That’s the first thing I should comment on is that the Shaw function makes sense.  Shaw function of spacing P makes sense as a distribution.

</p><p>Matter of fact let me specialize here, excuse me, to take the case P equals one, so the atoms are spaced one apart, then I’ll do the general case in just second.  So let me take the case, take P equals one, and again I’ll pass to the general case quite easily after I do this case.  So and I’ll draw out the subscripts.  So let me just write Shaw of X is sum from K equals minus infinity to infinity of delta X minus K.  All right, so the deltas are space on apart.  At every integer, you put a delta.

</p><p>Then this thing makes sense as a distribution.  Now again, why?  I tell you I have a distribution.  What that means is you give me a test function, I have to tell you how this operates on a test function.  Well it operates by evaluation.  In this case, I add up all the values.  That is the Shaw function operating on a test function phi, that’s the sum of shifted deltas operating on phi, that is just the sum from K equals minus infinity to infinity of phi evaluated at the points to which the delta – where the delta function is shifted.  Okay?  I won’t – I skipped a couple steps here but that’s what the result is and you can fill that in.

</p><p>Now why does this make sense?  Well if phi is a test function, and phi is rapidly decreasing, then it’s gonna be going down fast enough, way fast enough, so that this sum will converge.  All right?  Because the sum converges, the pairing makes sense.  All right?  So the sum converges so all is well, all right?

</p><p>So if this thing makes sense as a distribution, then so does this Fourier transform so this also make sense.  All right?  In fact, I can say this.  In fact, I can say that the Fourier transform of the Shaw function operating on phi is, by definition, the Shaw function operating on the Fourier transform of phi, classical Fourier transform, and I know what the Shaw function operating on the Fourier transform – operating on anything is, it’s just the value of the thing at – the sum of the values at the integer points.

</p><p>So this is the sum from K equals minus infinity to infinity of the Fourier transform of phi operating on K, evaluated to K.  So the Shaw function, again, operating on phi is the sum of deltas operating on phi.  Each delta operating on phi pulls out the value of phi at the place where the delta function is centered, phi of K, and I add them all up.  All right?

</p><p>The definition of the generalized Fourier transform is the Fourier transform of whatever distribution is operating on phi is the distribution operating on the Fourier transform of phi.  So it’s the Shaw function, again, operating on the Fourier transform of phi.  This is the sum of shifted deltas.  Each delta operates on this thing to evaluate at the place where the delta is shifted, so Fourier transform at K, and then you add them all up.  So it’s that result.  Okay?  But there is more to say.

</p><p>Now you could just look at the formula for the Shaw function and try to write it down as formula for the Fourier transform because you know the Fourier transform the individual delta functions.  All right?  You could write down the Fourier transform of the Shaw is the sum from K equals minus infinity to infinity, the Fourier transform of these delta functions.  And I know the Fourier transform of a shifted delta function is just the complex exponential.  That was one of our basic, one of the first formulas we derived when we were talking about generalized Fourier transforms.

</p><p>So I could write down this is equal to the sum from K equal minus infinity to infinity of E to the minus two pi IKS.  And you would be right to write that down.  That’s okay.  All right?  But it misses – that’s correct, but it misses the point.  This series is hard to consider, actually.  This series, again, doesn’t converge as a classical series.  I’m adding up – you think about it, I’m adding a bunch of sines and cosines here.  I’m adding a bunch of complex exponentials.  The coefficients in front are all one.  There’s no way that this series converges classically but it does make sense as a distribution.  All right?

</p><p>It doesn’t converge classically, all right, but it’s okay as a distribution and the formula’s right.  But okay as a distribution and it’s okay to say that the Fourier transform of the Shaw function is this sum of exponentials.  It’s okay but it misses the point.  But you’re missing something.  But you’re missing something, all right?  What you are missing actually is the deepest fact known about the integers, missing.

</p><p>To make this – to see the magic, and there really is some magic here, you bring in the so-called Poisson summation formula.  Okay?  You need the Poisson summation formula.  It is, as I say, one of my good friends who’s a number theorist, analytic number theorist, refers to this as the deepest fact known about the integers.  Once the Riemann hypothesis is proved, that’ll be the deepest fact known about the integers, but until that happens this is pretty deep.  And it’s also not so hard to prove.

</p><p>All right, it says the following.  It says if phi is a rapidly function, there are other classes for which this applies but this will be sufficient for our purposes, then if I add up the values of phi at all the integer points, that’s the same as adding up the values of the Fourier transform phi at all the integer points.  Fourier transform of phi.  Now this is an amazing, unexpected, not intuitive result.  The individual – I should call these K, sorry.  Sorry, sorry, sorry.  All right?

</p><p>The individual value, the value – I mean what, who cares about the integers, right?  I mean, you know, why would the value of the function at an integer come in and why would the value of the Fourier transform at an integer come in?  And the value of the function at a given integer has nothing to do, really nothing to do with the value of the Fourier transform at a given integer.  I mean there’s no relation there.  You can write down the formula for the interval and so on but there’s no – you shouldn’t expect any sort of special relationship with how big phi is at five versus how big the Fourier transform is at 5, or 10 or 6 or 17 or anything else.  All right?

</p><p>But the sum, so this is a case where it’s the limiting behavior and adding them all up, the sum of the values of the function phi at all the integer points is the same as the sum of the values of Fourier transform at all the integer points.  Okay?  Now I’m gonna prove that for you.

</p><p>It is an amazing fact and remarkable fact and I’d say the deepest fact known about the integers.  And in fact, if you took an undergraduate signals and systems class, you probably know this fact but you didn’t know you knew this fact.  Or, as I think I said in the book, the deepest fact about the integers is well known to every electrical engineer, and every material scientist for that matter, they just don’t know they know it.

</p><p>All right.  So I’m gonna give a prove of the Poisson summation formula.  How am I gonna do that?  All right I’m gonna periodize proof.  I think it’s the first time I’ve actually written that word on the board but I think it deserves it.  All right, so I’m gonna periodize phi.  So phi is, again, little phi is a given rapidly decreasing function, periodized phi to have period one.  All right, so what is that?  That is phi of – I call it capital phi of X is the sum from K equals minus infinity to infinity of phi of X minus K.  

</p><p>That’s the periodization, never mind bringing in the delta functions or anything like that, just think of the old days where we just wrote down that formula.  And that periodizes little phi to have period one.  Now everything is smooth here, everything is legit because phi is rapidly decreasing, the series converges, converges uniformly, it’s continuous, it’s everything you would want.  Don’t worry about it, don’t ask me about it, don’t get me any trouble.  All right?  Good.  

</p><p>Now capital phi being such a nice function has a Fourier series: expand phi, capital phi that is, in the Fourier series.  All right?  Good.  All right phi, phi of X is sum K equals minus infinity to infinity.  Phi hat K E to the two pi IKX.  Boom, got it, great.  All right?  That’s the Fourier series.

</p><p>I can see what you’re saying.  I finally got a math teacher who speaks English and he’s putting on an accent.  All right.

</p><p>Now what deal is this?  All right now you showed in the homework problem that there was a relationship between the Fourier coefficients of the periodized function and the Fourier transform of the original function that you periodized.  All right.  You showed – we know that the Fourier coefficient, the Nth of the K Fourier coefficient, of capital phi to periodized function is the Fourier transform of the function you were periodizing, also evaluated at K.  That was a homework problem.

</p><p>And so let me just plug that information in now.  All right?  And so phi of X, its Fourier series, K equals minus infinity to infinity, it’s the Fourier transform of the function you were periodizing times E to the two pi IKX.  All right?  That’s on the one hand.  That’s the Fourier series for capital phi.  On the other hand, phi was given actually as the periodization of little phi, so that’s the sum from K equals infinity to infinity of phi of X minus K.  Right?

</p><p>I have two expressions for the same thing.  This comes up a lot in this course, two expressions for the – if you have two expressions for the same thing you’ve got a lot of power over them, and the simplest thing to do here is just to evaluate at zero.  Evaluate at X equals zero.  All right?

</p><p>On the one hand, phi of zero, if I use the Fourier series expression, if I plug in X equals zero here I’m just adding up a bunch of ones times the Fourier transform.  Phi of zero is the sum from K equals minus infinity to infinity of F of phi K.  On the other hand, phi of zero, if I use the other expression, K equals minus infinity to infinity is phi of zero minus K, so phi of minus K.

</p><p>Well if I sum from – write this expression a little bit more neatly.  If I sum from minus to infinity to infinity, summing over – summing taking sum from minus infinity to infinity, phi of minus K is the same thing as summing K equals minus infinity to infinity of phi of K.  All right?  Where do we start?  Where do we finish?  What did I do?  What did I do?  What did I do?  I evaluated the same expression at two different – at the value zero; I get two different expressions for the same thing.  That is to say, I have proved my Poisson summation formula.

</p><p>So the sum of the Fourier coefficient, Fourier transform – excuse me, value of the Fourier transform, is the same thing as the sum of the values of the function at the integer points.  That deserves a couple of exclamation points, at least two.  Okay?  Wonderful.  Wonderful.

</p><p>Now let’s use this to find the Fourier transform of the Shaw function.  Let’s go back to that.  That’s what I wanted to get.  All right?  So back to the Fourier transform of the Shaw function.  What did we find?  We found that the Fourier transform of the Shaw function evaluated at phi was equal to the Shaw function evaluated at the Fourier – or paired with the Fourier transform of phi.  And again, that’s the sum from K equals minus infinity to infinity, the value of the Fourier transform of phi at the integer points.

</p><p>But now I invoke the Poisson summation formula.  This is so exciting.  This is equal to the sum from K equals minus infinity to infinity of phi of K.  But now remember, that this in turn is just the Shaw function itself evaluated or paired with phi.  Where do we start?  Where do we finish?  The Fourier transform of the Shaw function paired with phi is the same as the Shaw function paired with phi.  What is the conclusion?

</p><p>The conclusion is the Fourier transform of the Shaw function is the Shaw function, three exclamation points, although maybe I should put two because it’s entirely equivalent to the Poisson summation formula.  Entirely equivalent, okay?

</p><p>This is something that most, that many electrical engineers know.  All right?  This is equivalent to the Poisson summation formula.  This is equivalent to the deepest fact about the integers that is known.  All right?  And every electrical engineer who takes a sophomore level course on signals and systems probably knows this, although they may not know that they know it.  So again, it’s a little surprising here, right?  It’s very surprising.  Here’s the pictorially.  I mean here’s the original Shaw function spaced of – delta function spacing of the integers: minus one, two, minus two.  That’s the Shaw function, all right?

</p><p>I take the Fourier transform I get the same thing.  It’s a bunch of deltas again.  Not just the sum of complex exponentials or rather it is a sum of – it is an infinite sum of complex exponentials, but that’s infinite sum of complex exponentials, as a distribution, is actually the sum of deltas again.  So let me put it horizontally.  Take the Fourier transform I get the same thing: zero, one, minus one, two, same thing.  Okay, all right, very important fact, extremely important.

</p><p>Now let’s do the Shaw function with spacing P.  That is gonna follow from scaling properties of the delta function.  All right.  Now let’s do the Fourier transform of the Shaw function spacing P.  So remember the Shaw function with spacing P of X is this sum: sum from K equals minus infinity to infinity delta X minus KP, all right, same idea just different spacing.

</p><p>Okay, so let me work with the individual delta, show you what happens here.  So look at delta of X minus KP.  What I’m gonna do is factor a P out of this thing, all right?  So I’ll write this as delta of P times X over P minus K.  Now you remember what happens is the scaling – an important scaling property of a delta function, this is – do I have this right.  This is then one over P times the delta function at X over P minus K.  Okay?  Okay, did I get that right?  Yes.

</p><p>All right, so in other words, the Shaw function with spacing P at X is the same thing as the sum of these shifted delta functions.  So it’s the same thing as one over P times the sum from K equals minus infinity to infinity – well, it’s the Shaw function with spacing one evaluated at X over P.  All right, make sure you – I skipped a couple of steps there.

</p><p>Shaw function with spacing P, that’s the sum of these shifted delta functions.  That’s the same thing as one over P times the delta – so it’ll be a sum of a bunch of delta functions with spacing one apart but not evaluated at X, evaluated at X over P.  Okay?  So it’s one over P Shaw function with spacing X over P.  Do I have that right again?  I think so.

</p><p>So now if I take the Fourier transform of a Shaw function with spacing P, that’s the same thing as one over P, the Fourier transform of the Shaw function at X over P.  It’s like a scaled version of the Shaw function.  Okay?  All right so that is one over P – the – and I’ll use the scaling theorem.  The Fourier transform of X – the Fourier transform of this, right, is gonna be one over P.  The scaling factor comes out with a reciprocal, so it’s one over one over P, so it’s times P times the Fourier transform of the Shaw function evaluated at the reciprocal of the scaling factor, so it’ll be P times X.  Okay?

</p><p>The Fourier transform of the Shaw function itself is the Shaw function.  When there’s no spacing in there, when everything is spaced one apart, this is the Shaw function then at PX.  All right, one more step; we are almost there.

</p><p>What is the Shaw function at PX?  That will be the sum from K equals minus infinity to infinity delta of PX minus K.  So I’m gonna use the same scaling property of the delta function.  That is, I write this as delta PX minus K, I factor out the P.  That is, I write this as sum K equals minus infinity to infinity delta of P times X minus K over P.  Okay?  And pull that P out of the delta function.  I pull that P out of the delta function.  I get one over P sum from K equals minus infinity to infinity of the Shaw function at X minus K over P.  Okay?

</p><p>That’s just using the scaling property of the delta function because it’s delta P times something here, so it’s one over P times the delta of the something.  So it’s one over P times – and I’m adding them all up.  One over P times – oops, delta, delta, delta, delta.  All right.  All right?  That is the Shaw function of spacing one over P.  Right?  These points are spaced one over P apart.  In other words, this is one over P times the Shaw function with spacing one over P evaluated at X.

</p><p>All right once again, where do we start, where do we finish?  If you follow manipulations, what we showed was a very attractive formula.  Thus, the Fourier transform of the Shaw function with spacing P is one over P times the Shaw function with spacing one over P.  That is another very important formula; it gets two exclamation points itself and a couple underlines.  Works for P equals one.  For P equals one it reduces the case we had before.  All right?

</p><p>This is another wonderful illustration of the reciprocal relationship between the domain and the Fourier transform domain, the original domain and the original Fourier transform domain.  If the spacing in the original domain is P, then the spacing in the Fourier transform domain is one over P.  And they’re also scaled; the height is also scaled by one over P.  

</p><p>So again, here’s the Shaw function in the original domain, say, with spacing zero, P, minus P, two P, minus two P, and so on, going on to infinity.  I take the Fourier – this is Shaw P.  I take the Fourier transform and the spacing is one over P apart: zero, one over P, minus one over P, two over P, minus two over P, and so on.  And the height is also scaled by one over P.  Okay, extremely important.

</p><p>Let’s get back to our crystal, all right?  Now let’s get back to the crystal.  All right?  All of this was to help us get our Nobel Prize.  There’s a lot at stake.  And so back to the crystal, the spacing of the atom, the electron density distribution is described by rhos of P of X is rho of X convolved with the Shaw function with spacing P.  All right?  That is the periodized version of the electron density distribution for the crystal.  All right?  The atoms are spaced P apart.

</p><p>Now you do your diffraction experiment, all right?  You shine your x-rays through this crystal.  Hold your breath, good; get an exposure on the film.  What you see on your film is, essentially, the Fourier transform.  All right?  You see the Fourier transform of this.  So that’s the Fourier transform of rho convolved with Shaw sub P.  And what is that?  That’s the product of the Fourier transform of rho and the Fourier transform of the Shaw function with spacing P.

</p><p>The Shaw function with spacing phi has a Fourier transform spaced one over P.  That’s the Fourier transform of rho times one over P the Shaw function at one over P, one over P.  All right, let’s write this out one more step.  Okay?  Let me write it – let me write this out with the variables in there.

</p><p>Because this also involves the sampling property of the Shaw function – of the delta function, so this is F of rho of X times the Shaw function.  So this is sum K equals minus infinity to infinity, there’s one over P out in front of the whole thing, delta X minus K over P.  All right?  Now remember what happens if you multiply a function times the delta function.  All right?  That’s one over P sum, I’ll bring it inside I won’t skip a step, minus infinity to infinity, the Fourier transform of rho of X times delta X minus K over P.

</p><p>Multiply the sampling for the – yeah.  The sampling property of the delta function is if I multiply a function times delta that evaluates the function at K over P times the delta.  That is, this is equal to the sum from minus infinity to infinity, the Fourier transform of rho, one over P times the whole thing, evaluated at K over P times the delta function X minus K over P.  

</p><p>All right, we’re almost done.  What do you see in your – so this is what you see in your diffraction experiment.  All right?  You see this, now what are you really seeing in your diffraction experiment?  

</p><p>You are seeing a bunch of spots.  Imagine these things – and these are impulses at spaced – at points K over P, zero, one over P, two over P, three over P, and so on, minus one over P, minus two over P.  They have this intensity also scaled by one over P.  So you are seeing in your picture, you see a bunch of spots of intensity, the value of – density value evaluated there and then spaced at one over P part, zero, one over P, two over P, minus one over P, minus two over P, and so on.  Okay.

</p><p>You had to know this if you want to claim your Nobel Prize.  Why?  Because you might think that you do a diffraction experiment, the spacing of the spots is proportional to the spacing of the atoms.  All right, the atoms are spaced P apart.  You think you do an experiment, all right, the spacing, what I – I see a bunch of spots.  That must be proportional to the spacing.  But it’s not.  It’s proportional to the reciprocal of the spacing, all right?

</p><p>Nature is taking a Fourier transform for you.  And what you see, is you see a bunch of spots spaced on one over P apart, so you make this measurement.  And then you say that’s the reciprocal of the spacing in the atom, in the crystal.  That’s the reciprocal of the spacing in the crystal.  All right?  You have to know your math.  If you don’t know your math, kiss your Nobel Prize goodbye.  Okay?

</p><p>All right, that’s it for today.  Wasn’t that exciting?  And on Wednesday, we’re gonna make a different use of this and talk about sampling an interpolation.  Okay, thank you very much.
</p><p>
[End of Audio]
</p><p>
Duration:  53 minutes
</p><p>

</html>